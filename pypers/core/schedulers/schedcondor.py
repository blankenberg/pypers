import os
import sys
import subprocess
import copy
import re
from subprocess import Popen, PIPE,STDOUT
import schedabc
import time
import psutil
import tempfile
import collections
from schedabc import Scheduler, JOB_OUT, JOB_ERR
from pypers.config import ACME_PROD
from pypers.core.step import JOB_STATUS
from pypers.core.constants import LOG_NAME
from pypers.core.logger import logger
from pypers.utils.utils import format_dict

if ACME_PROD:
    TARGET_ENV = "PROD"
else:
    TARGET_ENV = "DEV"

#from src/condor_includes/proc.h 
CONDOR_JOB_STATUS = {
    "1" : JOB_STATUS.QUEUED,
    "2" : JOB_STATUS.RUNNING,              
    "3" : JOB_STATUS.INTERRUPTED, # REMOVED             
    "4" : JOB_STATUS.SUCCEEDED,            
    "5" : JOB_STATUS.INTERRUPTED, # HELD
    "6" : "TRANSFERRING_OUTPUT",  
    "7" : JOB_STATUS.INTERRUPTED
}


class CondorScheduler(Scheduler):

    # These just do cmd line submits of condor_status, condor_rm etc

    def __init__(self):
        """
        Just initialize the logger
        """
        self.log = logger.get_log()

    def submit(self,cmd,cmd_args,work_dir,reqs={}):
        """  
        Submits a job to the condor cluster.
        Returns the condor job id
        """

        # create a condor job description dictionary
        jdf_dict = collections.OrderedDict([
            ('Universe',   'vanilla'),
            ('GetEnv',     'True'),
            ('Initialdir', work_dir),
            ('Executable', cmd),
            ('Arguments',  ' '.join(cmd_args)),
            ('Log',     os.path.join(work_dir, 'condor.log')),
            ('Error',   os.path.join(work_dir, JOB_ERR)),
            ('Output',  os.path.join(work_dir, JOB_OUT))
        ])

        if TARGET_ENV == "DEV":
            jdf_dict.update(collections.OrderedDict([
                ('+%s' % TARGET_ENV, 'True'),
                ('Requirements', 'TARGET.%s' % TARGET_ENV)
                ])
            )

        if reqs.get('cpus'):
            jdf_dict.update({'RequestCpus' : int(reqs['cpus'])})

        if reqs.get('memory'):
            jdf_dict.update({'RequestMemory' : int(reqs['memory']) * 1024})

        # create a condor job description file
        jdfile = os.path.join(work_dir, 'condor.job')
        with open(jdfile, 'w') as jdfh:
            jdfh.write('# Condor submit file\n')
            jdfh.write('# Automatically generated by Pypers\n')
            for k,v in jdf_dict.iteritems():
                jdfh.write(k)
                if v:
                    jdfh.write(' = %s' % v)
                jdfh.write('\n')
            jdfh.write('Queue 1\n')

        # submit job
        submit_cmd = ['condor_submit', '-terse', jdfile] # -terse so that it returns the job id
        try:
            out = subprocess.check_output(submit_cmd)
        except subprocess.CalledProcessError, e:
            self.log.error('Failed to run command %s: %s' % (' '.join(submit_cmd), e))
            raise

        # catch jobid
        jobId = -1
        match = re.search("^\s*(\d+\.\d+)\s", out)
        if match:
            jobId = match.group(1)
        else:
            self.log.error('Unable to derive jobId from condor output: "%s"' % out)

        return jobId


    def stop(self, job_ids):
        """
        Stop all jobs in the list of job IDs
        """
        job_ids = set(job_ids)
        if job_ids:
            rm_cmd = ['condor_rm']
            rm_cmd.extend(job_ids)
            try:
                out = subprocess.check_output(rm_cmd)
                self.log.info(out)
            except subprocess.CalledProcessError, e:
                self.log.error('Problem running command %s: %s' % (' '.join(rm_cmd), e))
        else:
            self.log.info('No job needs to be stopped')


    def status(self, job_ids):
        """  
        Return the status of a Condor Job id using condor_q command
        """

        # Initialize status map from job ids
        job_ids = set(job_ids)
        status_map = dict.fromkeys(job_ids,'Unknown')

        # Check for running jobs first
        cmd = '/usr/bin/condor_q -format "%s" clusterid -format ".%s" procid -format " %s\\n" jobstatus ' + ' '.join(job_ids)
        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)

        remaining_ids = copy.copy(job_ids)
        for line in p.stdout:
            if re.search("^\d+\.\d+\s+\d+$", line):
                job_id, job_status = line.split()
                if job_id in job_ids:
                    status_map[job_id] = CONDOR_JOB_STATUS[job_status]
                    remaining_ids.remove(job_id)
            else:
                self.log.warn("could not get condor status")

        # Check in history if the job is really completed or failed
        if remaining_ids:
            constraint = '\'ClusterId==' + ' || ClusterId=='.join(remaining_ids) + '\' -match '+str(len(remaining_ids))
            cmd = 'condor_history -format "%v" clusterid -format ".%v" procid -format " %v" exitcode -format " %v" exitsignal -format " %v\\n" jobstatus -constraint ' + constraint

            p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
            for line in p.stdout:
                condor_history = line.split()
                if len(condor_history)==4:
                    job_id, exitcode, exitsignal, status = condor_history
                    if job_id in remaining_ids:
                        if exitcode=='0': # All good
                            status_map[job_id] = CONDOR_JOB_STATUS[status]
                        elif exitcode=='undefined' and exitsignal=='undefined': # Interrupted
                            status_map[job_id] = CONDOR_JOB_STATUS[status]
                        else:
                            status_map[job_id] = JOB_STATUS.FAILED
                elif len(condor_history)==2:
                    # Not sure it is still needed...
                    job_id, status = condor_history
                    if job_id in remaining_ids:
                        status_map[job_id] = CONDOR_JOB_STATUS[status]

        return status_map
